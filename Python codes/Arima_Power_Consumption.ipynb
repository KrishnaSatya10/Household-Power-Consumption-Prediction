{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "dataset = pd.read_csv('household_power_consumption.txt', sep=';', header=0, low_memory=False, infer_datetime_format=True, parse_dates={'datetime':[0,1]}, index_col=['datetime'], na_values=['nan','?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values per column....\n",
      "\n",
      "\n",
      "Global_active_power      25979\n",
      "Global_reactive_power    25979\n",
      "Voltage                  25979\n",
      "Global_intensity         25979\n",
      "Sub_metering_1           25979\n",
      "Sub_metering_2           25979\n",
      "Sub_metering_3           25979\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of null values per column\n",
    "\n",
    "print(\"Number of null values per column....\")\n",
    "print('\\n')\n",
    "print(dataset.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values per column  Global_active_power      0\n",
      "Global_reactive_power    0\n",
      "Voltage                  0\n",
      "Global_intensity         0\n",
      "Sub_metering_1           0\n",
      "Sub_metering_2           0\n",
      "Sub_metering_3           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Handling missing values using forward interpolation method\n",
    "dataset.interpolate(method='linear',limit_direction='forward', axis=0, inplace=True)\n",
    "print(\"Number of null values per column \",dataset.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2075259, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('household_power_consumption.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1442, 7)\n",
      "            Global_active_power  Global_reactive_power    Voltage  \\\n",
      "datetime                                                            \n",
      "2006-12-16             1209.176                 34.922   93552.53   \n",
      "2006-12-17             3390.460                226.006  345725.32   \n",
      "2006-12-18             2203.826                161.792  347373.64   \n",
      "2006-12-19             1666.194                150.942  348479.01   \n",
      "2006-12-20             2225.748                160.998  348923.61   \n",
      "\n",
      "            Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
      "datetime                                                                      \n",
      "2006-12-16            5180.8             0.0           546.0          4926.0  \n",
      "2006-12-17           14398.6          2033.0          4187.0         13341.0  \n",
      "2006-12-18            9247.2          1063.0          2621.0         14018.0  \n",
      "2006-12-19            7094.0           839.0          7602.0          6197.0  \n",
      "2006-12-20            9313.0             0.0          2648.0         14063.0  \n"
     ]
    }
   ],
   "source": [
    "# load the new file\n",
    "dataset = pd.read_csv('household_power_consumption.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "# resample data to daily\n",
    "daily_groups = dataset.resample('D')\n",
    "daily_data = daily_groups.sum()\n",
    "# summarize\n",
    "print(daily_data.shape)\n",
    "print(daily_data.head())\n",
    "# save\n",
    "daily_data.to_csv('household_power_consumption_days.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 7)\n",
      "            Global_active_power  Global_reactive_power     Voltage  \\\n",
      "datetime                                                             \n",
      "2006-12-17             4599.636                260.928   439277.85   \n",
      "2006-12-24            17477.618               1176.174  2433008.21   \n",
      "2006-12-31            19749.552               1453.126  2438445.48   \n",
      "2007-01-07            14961.068               1348.954  2428490.09   \n",
      "2007-01-14            16179.547               1590.541  2421917.62   \n",
      "\n",
      "            Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
      "datetime                                                                      \n",
      "2006-12-17           19579.4          2033.0          4733.0         18267.0  \n",
      "2006-12-24           73994.4         11190.0         21351.0         77447.0  \n",
      "2006-12-31           83078.0         14312.0         22675.0         67272.0  \n",
      "2007-01-07           63122.2          5857.0         17599.0         54193.0  \n",
      "2007-01-14           68864.8         13420.0         18989.0         83372.5  \n"
     ]
    }
   ],
   "source": [
    "# load the new file\n",
    "dataset = pd.read_csv('household_power_consumption.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "# resample data to daily\n",
    "daily_groups = dataset.resample('W')\n",
    "daily_data = daily_groups.sum()\n",
    "# summarize\n",
    "print(daily_data.shape)\n",
    "print(daily_data.head())\n",
    "# save\n",
    "daily_data.to_csv('household_power_consumption_weeks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 7)\n",
      "            Global_active_power  Global_reactive_power       Voltage  \\\n",
      "datetime                                                               \n",
      "2006-12-31            41826.806               2890.228  5.310732e+06   \n",
      "2007-01-31            69017.296               5922.929  1.075399e+07   \n",
      "2007-02-28            56496.828               4581.798  9.697733e+06   \n",
      "2007-03-31            58862.721               5122.412  1.073652e+07   \n",
      "2007-04-30            36529.192               5221.383  1.032721e+07   \n",
      "\n",
      "            Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
      "datetime                                                                      \n",
      "2006-12-31          176651.8         27535.0         48759.0        162986.0  \n",
      "2007-01-31          292264.4         56433.0         79274.5        329610.5  \n",
      "2007-02-28          238497.0         47584.0         64640.0        270308.0  \n",
      "2007-03-31          248774.5         60769.0        104762.0        290361.0  \n",
      "2007-04-30          156983.0         42078.0         38417.0        189503.0  \n"
     ]
    }
   ],
   "source": [
    "# load the new file\n",
    "dataset = pd.read_csv('household_power_consumption.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "# resample data to daily\n",
    "daily_groups = dataset.resample('M')\n",
    "daily_data = daily_groups.sum()\n",
    "# summarize\n",
    "print(daily_data.shape)\n",
    "print(daily_data.head())\n",
    "# save\n",
    "daily_data.to_csv('household_power_consumption_months.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Global_active_power case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for days case\n",
    "dataset = read_csv('household_power_consumption_days.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for weeks case\n",
    "dataset = read_csv('household_power_consumption_weeks.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for months case\n",
    "dataset = read_csv('household_power_consumption_months.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47137.75875"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(dataset['Global_active_power'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "def test_stationarity(timeseries, window = 12, cutoff = 0.01):\n",
    "\n",
    "    #Determing rolling statistics\n",
    "    rolmean = timeseries.rolling(window).mean()\n",
    "    rolstd = timeseries.rolling(window).std()\n",
    "\n",
    "    #Plot rolling statistics:\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show()\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC', maxlag = 20 )\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    pvalue = dftest[1]\n",
    "    if pvalue < cutoff:\n",
    "        print('p-value = %.4f. The series is likely stationary.' % pvalue)\n",
    "    else:\n",
    "        print('p-value = %.4f. The series is likely non-stationary.' % pvalue)\n",
    "    \n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Dickey-Fuller Test:\n",
      "p-value = 0.0038. The series is likely stationary.\n",
      "Test Statistic                  -3.719967\n",
      "p-value                          0.003841\n",
      "#Lags Used                       2.000000\n",
      "Number of Observations Used    204.000000\n",
      "Critical Value (1%)             -3.462818\n",
      "Critical Value (5%)             -2.875815\n",
      "Critical Value (10%)            -2.574379\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "test_stationarity(dataset['Global_active_power'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Global_active_power case after differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Dickey-Fuller Test:\n",
      "p-value = 0.0000. The series is likely stationary.\n",
      "Test Statistic                -1.484073e+01\n",
      "p-value                        1.838843e-27\n",
      "#Lags Used                     1.000000e+00\n",
      "Number of Observations Used    2.040000e+02\n",
      "Critical Value (1%)           -3.462818e+00\n",
      "Critical Value (5%)           -2.875815e+00\n",
      "Critical Value (10%)          -2.574379e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "first_diff = dataset['Global_active_power'] - dataset['Global_active_power'].shift(1)\n",
    "first_diff = first_diff.dropna(inplace = False)\n",
    "test_stationarity(first_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACF and PACF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use the ACF and PACF plots to determine (p,d,q) parameters for the Arima Model. \n",
    "\n",
    "#### 'p' represents the number of AR terms\n",
    "#### 'd' represents the the Integrative part of the model, i.e. if the data is non-stationary then which difference to take\n",
    "#### 'q' represents the number of MA term\n",
    "\n",
    "#### From the ACF plot we can learn if or how many MA terms to add and from the PACF plot we can learn if or how many AR terms to add.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Global_active_power case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(dataset['Global_active_power'], lags=50, ax=ax1) # \n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(dataset['Global_active_power'], lags=50, ax=ax2)# , lags=40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Global_active_power case after differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(first_diff, lags=50, ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(first_diff, lags=50, ax=ax2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arima: [408.145] 399.7, 417.1, 428.9, 394.2, 407.4, 311.0, 479.8\n"
     ]
    }
   ],
   "source": [
    "# arima forecast\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def split_dataset(data):\n",
    "# split into standard weeks\n",
    "\ttrain, test = data[1:-328], data[-328:-6]\n",
    "\t# restructure into windows of weekly data\n",
    "\ttrain = array(split(train, len(train)/7))\n",
    "\ttest = array(split(test, len(test)/7))\n",
    "\treturn train, test\n",
    "\n",
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "\tscores = list()\n",
    "\t# calculate an RMSE score for each day\n",
    "\tfor i in range(actual.shape[1]):\n",
    "\t\t# calculate mse\n",
    "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "\t\t# calculate rmse\n",
    "\t\trmse = sqrt(mse)\n",
    "\t\t# store\n",
    "\t\tscores.append(rmse)\n",
    "\t# calculate overall RMSE\n",
    "\ts = 0\n",
    "\tfor row in range(actual.shape[0]):\n",
    "\t\tfor col in range(actual.shape[1]):\n",
    "\t\t\ts += (actual[row, col] - predicted[row, col])**2\n",
    "\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "\treturn score, scores\n",
    "\n",
    "# summarize scores\n",
    "def summarize_scores(name, score, scores):\n",
    "\ts_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "\tprint('%s: [%.3f] %s' % (name, score, s_scores))\n",
    "\n",
    "# evaluate a single model\n",
    "def evaluate_model(model_func, train, test):\n",
    "\t# history is a list of weekly data\n",
    "\thistory = [x for x in train]\n",
    "\t# walk-forward validation over each week\n",
    "\tpredictions = list()\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# predict the week\n",
    "\t\tyhat_sequence = model_func(history)\n",
    "\t\t# store the predictions\n",
    "\t\tpredictions.append(yhat_sequence)\n",
    "\t\t# get real observation and add to history for predicting the next week\n",
    "\t\thistory.append(test[i, :])\n",
    "\tpredictions = array(predictions)\n",
    "\t# evaluate predictions days for each week\n",
    "\tscore, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "\treturn score, scores, predictions\n",
    "\n",
    "# convert windows of weekly multivariate data into a series of total power\n",
    "def to_series(data):\n",
    "\t# extract just the total power from each week\n",
    "\tseries = [week[:, 0] for week in data]\n",
    "\t# flatten into a single series\n",
    "\tseries = array(series).flatten()\n",
    "\treturn series\n",
    "\n",
    "# arima forecast\n",
    "def arima_forecast(history):\n",
    "\t# convert history into a univariate series\n",
    "\tseries = to_series(history)\n",
    "\t# define the model\n",
    "\tmodel = ARIMA(series, order=(7,0,0))    \n",
    "\t# fit the model\n",
    "\tmodel_fit = model.fit()\n",
    "\t# make forecast\n",
    "\tyhat = model_fit.predict(len(series), len(series)+6)\n",
    "\treturn yhat\n",
    "\n",
    "# load the new file\n",
    "#dataset = read_csv('household_power_consumption_days.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "\n",
    "dataset = read_csv('household_power_consumption_days.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "\n",
    "# split into train and test\n",
    "train, test = split_dataset(dataset.values)\n",
    "# define the names and functions for the models we wish to evaluate\n",
    "models = dict()\n",
    "models['arima'] = arima_forecast\n",
    "# evaluate each model\n",
    "days = ['sun', 'mon', 'tue', 'wed', 'thr', 'fri', 'sat']\n",
    "for name, func in models.items():\n",
    "\t# evaluate and get scores\n",
    "\tscore, scores, predictions = evaluate_model(func, train, test)\n",
    "\t# summarize scores\n",
    "\tsummarize_scores(name, score, scores)\n",
    "\t# plot scores\n",
    "\tpyplot.plot(days, scores, marker='o', label=name)\n",
    "# show plot\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean square error (RMSE) is: 408.1446241449729 kilowatts\n",
      "Mean absolute percentage error is: 24.301575909193563\n",
      "Mean Absolute Error is: 312.8943078546951 \n"
     ]
    }
   ],
   "source": [
    "#calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(test[:, :, 0].flatten(),predictions.flatten())) \n",
    "print(f'Root mean square error (RMSE) is: {rmse} kilowatts')\n",
    "mape = np.mean(np.abs((test[:, :, 0].flatten() - predictions.flatten()) /test[:, :, 0].flatten())) * 100\n",
    "print(f'Mean absolute percentage error is: {mape}')\n",
    "mae_error = mae(test[:, :, 0].flatten(),predictions.flatten())\n",
    "print(f'Mean Absolute Error is: {mae_error} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "pyplot.plot(np.linspace(1,322,322), test[:, :, 0].flatten(), marker='o', label='actual')\n",
    "pyplot.plot(np.linspace(1,322,322), predictions.flatten(), marker='x', label='predicted')\n",
    "pyplot.legend(['actual', 'predicted'])\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Global_active_power (in Kilowatts)')\n",
    "plt.title('Actual vs. Predicted for daily case')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arima: [2126.841] 2176.6, 2492.7, 1627.2, 2120.1\n"
     ]
    }
   ],
   "source": [
    "# arima forecast\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def split_dataset(data):\n",
    "# split into standard months\n",
    "\ttrain, test = data[3:159], data[159:]\n",
    "\t# restructure into windows of monthly data\n",
    "\ttrain = array(split(train, len(train)/4))\n",
    "\ttest = array(split(test, len(test)/4))\n",
    "\treturn train, test\n",
    "\n",
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "\tscores = list()\n",
    "\t# calculate an RMSE score for week day\n",
    "\tfor i in range(actual.shape[1]):\n",
    "\t\t# calculate mse\n",
    "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "\t\t# calculate rmse\n",
    "\t\trmse = sqrt(mse)\n",
    "\t\t# store\n",
    "\t\tscores.append(rmse)\n",
    "\t# calculate overall RMSE\n",
    "\ts = 0\n",
    "\tfor row in range(actual.shape[0]):\n",
    "\t\tfor col in range(actual.shape[1]):\n",
    "\t\t\ts += (actual[row, col] - predicted[row, col])**2\n",
    "\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "\treturn score, scores\n",
    "\n",
    "# summarize scores\n",
    "def summarize_scores(name, score, scores):\n",
    "\ts_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "\tprint('%s: [%.3f] %s' % (name, score, s_scores))\n",
    "\n",
    "# evaluate a single model\n",
    "def evaluate_model(model_func, train, test):\n",
    "\t# history is a list of monthly data\n",
    "\thistory = [x for x in train]\n",
    "\t# walk-forward validation over each month\n",
    "\tpredictions = list()\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# predict the month\n",
    "\t\tyhat_sequence = model_func(history)\n",
    "\t\t# store the predictions\n",
    "\t\tpredictions.append(yhat_sequence)\n",
    "\t\t# get real observation and add to history for predicting the next month\n",
    "\t\thistory.append(test[i, :])\n",
    "\tpredictions = array(predictions)\n",
    "\t# evaluate predictions days for each month\n",
    "\tscore, scores = evaluate_forecasts(test[:, :], predictions)\n",
    "\treturn score, scores, predictions\n",
    "\n",
    "# convert windows of weekly multivariate data into a series of total power\n",
    "def to_series(data):\n",
    "\t# extract just the total power from each month\n",
    "\tseries = [month[:] for month in data]\n",
    "\t# flatten into a single series\n",
    "\tseries = array(series).flatten()\n",
    "\treturn series\n",
    "\n",
    "# arima forecast\n",
    "def arima_forecast(history):\n",
    "\t# convert history into a univariate series\n",
    "\tseries = to_series(history)\n",
    "\t# define the model\n",
    "\tmodel = ARIMA(series, order=(4,0,4))    \n",
    "\t# fit the model\n",
    "\tmodel_fit = model.fit()\n",
    "\t# make forecast\n",
    "    \n",
    "\tyhat = model_fit.predict(len(series), len(series)+3)\n",
    "\treturn yhat\n",
    "\n",
    "# load the new file\n",
    "\n",
    "dataset = read_csv('household_power_consumption_weeks.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "\n",
    "dataset = dataset['Global_active_power']\n",
    "# split into train and test\n",
    "train, test = split_dataset(dataset.values)\n",
    "# define the names and functions for the models we wish to evaluate\n",
    "models = dict()\n",
    "models['arima'] = arima_forecast\n",
    "# evaluate each model\n",
    "days = ['Week1', 'Week2', 'Week3', 'Week4']\n",
    "for name, func in models.items():\n",
    "\t# evaluate and get scores\n",
    "\tscore, scores, predictions = evaluate_model(func, train, test)\n",
    "\t# summarize scores\n",
    "\tsummarize_scores(name, score, scores)\n",
    "\t# plot scores\n",
    "\tpyplot.plot(days, scores, marker='o', label=name)\n",
    "# show plot\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean square error (RMSE) is: 2126.8405602353782 kilowatts\n",
      "Mean absolute percentage error is: 20.0523456377624\n",
      "Mean Absolute Error is: 1543.1376370421615 \n"
     ]
    }
   ],
   "source": [
    "#calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(test[:, :].flatten(),predictions.flatten())) \n",
    "print(f'Root mean square error (RMSE) is: {rmse} kilowatts')\n",
    "mape = np.mean(np.abs((test[:, :].flatten() - predictions.flatten()) /test[:, :].flatten())) * 100\n",
    "print(f'Mean absolute percentage error is: {mape}')\n",
    "mae_error = mae(test[:, :].flatten(),predictions.flatten())\n",
    "print(f'Mean Absolute Error is: {mae_error} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "pyplot.plot(np.linspace(1,48,48), test[:, :].flatten(), marker='o', label='actual')\n",
    "pyplot.plot(np.linspace(1,48,48), predictions.flatten(), marker='x', label='predicted')\n",
    "pyplot.legend(['actual', 'predicted'])\n",
    "plt.xlabel('Weeks')\n",
    "plt.ylabel('Global_active_power (in Kilowatts)')\n",
    "plt.title('Actual vs. Predicted for Weekly case')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For months\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sharva\\Anaconda3\\envs\\alda2\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:868: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  ' zeros.' % warning_description)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arima: [8714.432] 8874.6, 10334.8, 7175.1, 4201.6, 6302.6, 16704.0, 13493.1, 2575.1, 9418.3, 5421.6, 1769.8, 5284.2\n"
     ]
    }
   ],
   "source": [
    "# arima forecast\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def split_dataset(data):\n",
    "# split into standard years\n",
    "\ttrain, test = data[:36], data[36:]\n",
    "\t# restructure into windows of yearly data\n",
    "\ttrain = array(split(train, len(train)/12))\n",
    "\ttest = array(split(test, len(test)/12))\n",
    "\treturn train, test\n",
    "\n",
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "\tscores = list()\n",
    "\t# calculate an RMSE score for each month\n",
    "\tfor i in range(actual.shape[1]):\n",
    "\t\t# calculate mse\n",
    "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "\t\t# calculate rmse\n",
    "\t\trmse = sqrt(mse)\n",
    "\t\t# store\n",
    "\t\tscores.append(rmse)\n",
    "\t# calculate overall RMSE\n",
    "\ts = 0\n",
    "\tfor row in range(actual.shape[0]):\n",
    "\t\tfor col in range(actual.shape[1]):\n",
    "\t\t\ts += (actual[row, col] - predicted[row, col])**2\n",
    "\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "\treturn score, scores\n",
    "\n",
    "# summarize scores\n",
    "def summarize_scores(name, score, scores):\n",
    "\ts_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "\tprint('%s: [%.3f] %s' % (name, score, s_scores))\n",
    "\n",
    "# evaluate a single model\n",
    "def evaluate_model(model_func, train, test):\n",
    "\t# history is a list of yearly data\n",
    "\thistory = [x for x in train]\n",
    "\t# walk-forward validation over each year\n",
    "\tpredictions = list()\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# predict the week\n",
    "\t\tyhat_sequence = model_func(history)\n",
    "\t\t# store the predictions\n",
    "\t\tpredictions.append(yhat_sequence)\n",
    "\t\t# get real observation and add to history for predicting the next year\n",
    "\t\thistory.append(test[i, :])\n",
    "\tpredictions = array(predictions)\n",
    "\t# evaluate predictions days for each year\n",
    "\tscore, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "\treturn score, scores, predictions\n",
    "\n",
    "# convert windows of weekly multivariate data into a series of total power\n",
    "def to_series(data):\n",
    "\t# extract just the total power from each year\n",
    "\tseries = [year[:, 0] for year in data]\n",
    "\t# flatten into a single series\n",
    "\tseries = array(series).flatten()\n",
    "\treturn series\n",
    "\n",
    "# arima forecast\n",
    "def arima_forecast(history):\n",
    "\t# convert history into a univariate series\n",
    "\tseries = to_series(history)\n",
    "\t# define the model\n",
    "\tmodel = ARIMA(series, order=(12,1,12))    \n",
    "\t# fit the model\n",
    "\tmodel_fit = model.fit()\n",
    "\t# make forecast\n",
    "\tyhat = model_fit.predict(len(series), len(series)+11)\n",
    "\treturn yhat\n",
    "\n",
    "# load the new file\n",
    "#dataset = read_csv('household_power_consumption_days.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "\n",
    "dataset = read_csv('household_power_consumption_months.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "\n",
    "# split into train and test\n",
    "train, test = split_dataset(dataset.values)\n",
    "# define the names and functions for the models we wish to evaluate\n",
    "models = dict()\n",
    "models['arima'] = arima_forecast\n",
    "# evaluate each model\n",
    "days = ['Jan', 'Feb', 'March', 'Apr', 'May', 'June', 'July', 'Aug', 'Sep','Oct','Nov','Dec']\n",
    "for name, func in models.items():\n",
    "\t# evaluate and get scores\n",
    "\tscore, scores, predictions = evaluate_model(func, train, test)\n",
    "\t# summarize scores\n",
    "\tsummarize_scores(name, score, scores)\n",
    "\t# plot scores\n",
    "\tpyplot.plot(days, scores, marker='o', label=name)\n",
    "# show plot\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean square error (RMSE) is: 8714.431736240027 kilowatts\n",
      "Mean absolute percentage error is: 16.860117513990104\n",
      "Mean Absolute Error is: 7629.570202349165 \n"
     ]
    }
   ],
   "source": [
    "#calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(test[:, :, 0].flatten(),predictions.flatten())) \n",
    "print(f'Root mean square error (RMSE) is: {rmse} kilowatts')\n",
    "mape = np.mean(np.abs((test[:, :, 0].flatten() - predictions.flatten()) /test[:, :, 0].flatten())) * 100\n",
    "print(f'Mean absolute percentage error is: {mape}')\n",
    "mae_error = mae(test[:, :, 0].flatten(),predictions.flatten())\n",
    "print(f'Mean Absolute Error is: {mae_error} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "pyplot.plot(np.linspace(1,12,12), test[:, :, 0].flatten(), marker='o', label='actual')\n",
    "pyplot.plot(np.linspace(1,12,12), predictions.flatten(), marker='x', label='predicted')\n",
    "pyplot.legend(['actual', 'predicted'])\n",
    "plt.xlabel('Months')\n",
    "plt.ylabel('Global_active_power (in Kilowatts)')\n",
    "plt.title('Actual vs. Predicted for monthly case')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
